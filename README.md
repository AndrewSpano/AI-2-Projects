# Natural Language Processing Projects

This repo contains solutions to the projects which were assigned for the Artifical Intelligence II course of the [Department of Informatics and Telecommunications](https://www.di.uoa.gr/en) at the University of Athens, Greece. The course was specialized in Deep Learning for [Natural Language Processing](https://en.wikipedia.org/wiki/Natural_language_processing) (NLP).
<br> </br>


## Project 1

The main tasks in this project were to

1. Implement a [Ridge Regressor](https://en.wikipedia.org/wiki/Tikhonov_regularization) from scratch, along with the [batch](https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a), [stochastic](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) and [mini-batch](https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/) gradient descent algorithms.
2. Develop a [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) classifier for a given twitter dataset using the [scikit-learn](https://scikit-learn.org/stable/) python library.
<br> </br>


## Project 2

The main tasks in this project were to

1. Solve some theoretical questions.
2. Implement 2 different [Feed Forward Neural Network](https://en.wikipedia.org/wiki/Artificial_neural_network) sentiment classifiers for the same dataset used in the first Project. One of them uses the [GloVe](https://en.wikipedia.org/wiki/Artificial_neural_network) pre-trained word embeddings.
<br> </br>


## Project 3

The main task in this project was to develop and expetiment with different [Recurrent Neural Network](https://en.wikipedia.org/wiki/Recurrent_neural_network) architectures (i.e. [GRU](https://en.wikipedia.org/wiki/Gated_recurrent_unit), [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory)) in order to build a classifier for the datased used in the first project. Then, an [attention mechanism](https://en.wikipedia.org/wiki/Attention_(machine_learning)) was added to the RNN in order to improve performance.
<br> </br>


## Project 4

The main tasks in this project were to

1. Implement a [Text Retrieval](https://en.wikipedia.org/wiki/Document_retrieval) system using pre-trained [Sentence-BERT](https://arxiv.org/abs/1908.10084) models.
2. Implement a [Question Answering](https://en.wikipedia.org/wiki/Question_answering) system for the [SQuAD2.0](https://rajpurkar.github.io/SQuAD-explorer/) using the [BERT](https://en.wikipedia.org/wiki/BERT_(language_model)) model "[bert-base-uncased](https://huggingface.co/bert-base-uncased)" as a basis.
<br> </br>


## Project 5

The task in this project was to write some question in Natural Language that can be used to evaluate a Geographical Question Answering System.
<br> </br>


All the programming solutions to the projects were implemented in [Google Colabs](https://colab.research.google.com/). The Deep Learning Framework that was used to solve the projects is [PyTorch](https://pytorch.org/).